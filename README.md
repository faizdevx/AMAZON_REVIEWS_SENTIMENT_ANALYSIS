# ğŸ¤– Sentiment Analysis with BERT (Hugging Face Transformers)

A state-of-the-art sentiment classifier fine-tuned using `bert-base-uncased` on Amazon product reviews.  
This project replaces traditional ML methods (TF-IDF + Logistic Regression) with a Transformer-based model for **enhanced performance** and **portfolio impact**.

---

## ğŸ“ Dataset

- **Source**: Amazon product review dataset  
- **Shape**: 20,000 samples  
- **Columns**:
  - `reviewText` â€” customer-written product reviews  
  - `Positive` â€” binary sentiment label (`1 = positive`, `0 = negative`)

---

## ğŸ”§ Model Architecture

- **Model**: BERT (`bert-base-uncased`)  
- **Framework**: Hugging Face Transformers  
- **Tokenization**: Max length 128, with truncation and padding  

**Training Configuration**:
- Epochs: **3**
- Batch size: **16**
- Optimizer: **AdamW** with learning rate `2e-5`
- Device: **Colab GPU**
- Monitoring: **Weights & Biases (W&B)** *(optional)*

---

## ğŸ“Š Performance Summary

| Epoch | Accuracy | F1 Score | Precision | Recall | Val Loss |
|-------|----------|----------|-----------|--------|----------|
| 1     | 95.45%   | 0.970    | 0.969     | 0.971  | 0.1603   |
| 2     | 95.70%   | 0.972    | 0.972     | 0.972  | 0.1888   |
| 3     | 95.40%   | 0.970    | 0.972     | 0.967  | 0.2258   |

- âœ… **Final Accuracy**: **95.7%**
- âœ… **Final Training Loss**: **0.103**
- âœ… **F1-Score**: **0.972**

---

## ğŸ†š Accuracy Comparison (Baseline vs BERT)

| Model                        | Accuracy | F1 Score |
|-----------------------------|----------|----------|
| TF-IDF + Logistic Regression| 85.2%    | 84.7%    |
| BERT (Fine-Tuned)           | 95.7%    | 97.2%    |

ğŸ¯ **+10.5% Accuracy Boost using Transformers!**

---

## ğŸ§  Misclassification Insights

### Confusion Matrix

![Confusion Matrix](images/confusion_matrix.png)

### Sarcasm Detection is Tough:
> *â€œYeah, perfect. Just what I wanted â€” more popups ğŸ™„â€*  
> **Predicted**: Positive  
> **Actual**: Negative

### Context-loss in Short Reviews:
> *â€œNice.â€*  
> Too short and ambiguous to infer clear sentiment

---

## ğŸ“Œ Summary

- âœ… **Transformer models** like BERT offer significant gains over traditional ML approaches  
- ğŸ” Still, nuanced contexts like **sarcasm** or **very short reviews** remain a challenge  
- ğŸ“ˆ Ideal for portfolio projects showcasing **real-world NLP applications**

---


## ğŸ“ Project Structure


ğŸ“¦ sentiment-bert
 â”£ ğŸ“œ amazon.csv
 â”£ ğŸ“œ sentiment_analysis.ipynb
 â”£ ğŸ“œ README.md
 â”£ ğŸ“‚ images
 â”ƒ â”— ğŸ“· confusion_matrix.png




## ğŸš€ Deployment Plan

### âœ… Option 1: Streamlit App
- Build an interactive UI  
- User types a review and receives:
  - **Sentiment prediction**
  - **Confidence score**

---

### âœ… Option 2: Hugging Face Spaces
- Use **Gradio** or **Streamlit** for interface  
- Easy-to-deploy, cloud-hosted model  
- **No backend/server required** â€” fully managed by Hugging Face


## Future Plan 
- train my model to act and give answer perfectly on multilingual reviews also 
